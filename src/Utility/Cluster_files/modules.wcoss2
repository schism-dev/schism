Currently Loaded Modules:
  1) craype-x86-rome     (H)   5) cmake/3.20.2         9) cray-mpich/8.1.9  13) subversion/1.14.0  17) udunits/2.2.28   21) cfp/2.0.4
  2) libfabric/1.11.0.0. (H)   6) PrgEnv-intel/8.1.0  10) cray-pals/1.0.17  14) python/3.8.6       18) libjpeg/9c       22) gsl/2.7
  3) craype-network-ofi  (H)   7) craype/2.7.10       11) netcdf/4.7.4      15) prod_envir/2.0.6   19) grib_util/1.2.2  23) nco/4.9.7
  4) envvar/1.0                8) intel/19.1.3.304    12) hdf5/1.10.6       16) prod_util/2.0.13   20) wgrib2/2.0.8     24) awscli/1.16.308

export  NetCDF_INCLUDE_DIR=$NETCDF_INCLUDES
export  NetCDF_LIBRARIES=$NetCDF_LIBRARIES
export  NetCDF_FORTRAN_DIR=$NETCDF
export  TVD_LIM=VL


For large meshes (e.g. from OWP), it's also necessary to set these in the batch script:

export FI_OFI_RXM_SAR_LIMIT=3145728
export FI_MR_CACHE_MAX_COUNT=0

Zhengtao used 64 cores/nodes.

Below is from Zizang on STOFS3D-Atlantic setting on WCOSS2:
Total nodes: 29
Number of mpi processors: 128
Key MPI parameter setup1:
- export MPICH_OFI_STARTUP_CONNECT=1 a
- export MPICH_COLL_SYNC=MPI_Bcast b
- export MPICH_REDUCE_NO_SMP=1 c
a Purpose: set up MPI connections and buffers at start of run - helps efficiency of MPI later in run
b Pace MPI_Bcast messaging when reading and distributing initial conditions - prevents the Bcast hangs
c Turn off MPI_Reduce on node optimization - prevent MPI_Reduce hangs during time stepping

