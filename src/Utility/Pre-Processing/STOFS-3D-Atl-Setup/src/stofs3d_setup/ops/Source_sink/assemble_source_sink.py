"""
Assemble source/sink files for SCHISM model
"""

import os
import numpy as np
import json
from pathlib import Path

from .NWM.gen_sourcesink_nwm import gen_sourcesink_nwm
from .Constant_sinks.set_constant_sink import set_constant_sink
from .Relocate.relocate_source_feeder import relocate_sources2
from .Replace_with_USGS.replace_with_obs import source_nwm2usgs
from ...utils.utils import mkcd_new_dir, STOFS3D_ATL_STATES
from pylib_experimental.schism_file import source_sink, TimeHistory


script_path = os.path.dirname(os.path.realpath(__file__))


def gen_relocated_source(original_source_sink_dir, relocated_source_sink_dir):
    """
    Generate relocated vsource.th for STOFS-3D-ATL
    based on sources.json and sinks.json generated by relocate_sources2
    """

    original_ss = source_sink.from_files(source_dir=original_source_sink_dir)

    original_ele_nwm_mapping = json.load(
        open(f'{original_source_sink_dir}/sources.json', 'r')
    )
    # reverse the mapping
    original_nwm_ele_mappping = {}
    potential_duplicates = {}
    for ele, nwm_fids in original_ele_nwm_mapping.items():

        if len(nwm_fids) > 1:
            print(
                f'Warning: original source element {ele} is mapped to multiple NWM feature IDs: {nwm_fids}. '
                'This can happen if multiple NWM segments intersect with the same element. '
                'In this case, there is likely only one large river'
            )
            print(f'mean flow of ele {ele} (no-feeder mesh): {original_ss.vsource.df[ele].values.mean()}')
            potential_duplicates[ele] = original_ss.vsource.df[ele].values.mean()
        for nwm_fid in nwm_fids:
            if nwm_fid in original_nwm_ele_mappping:
                print(
                    f"Warning: NWM feature ID {nwm_fid} is already mapped to "
                    f"{original_nwm_ele_mappping[nwm_fid]}. Overwriting with {ele}"
                )  # if an nwm_fid is mapped to multiple elements, keep the last one.

                # This can happen if the original source_sink is generated by pyschism,
                # with an NWM segment weaving in and out of multiple elements,
                # resulting in multiple sources and sinks maped to the same nwm_fid.
                # However, the relocation process will ignore all sinks, so only one source
                # should be mapped to the same nwm_fid. And the exact location is somewhat arbitrary.
                # In a rare case, a river can go in as one nwm_fid and out as another nwm_fid,
                # so make sure this doesn't happen by properly aligning the schism land boundary
                # and avoid NWM segments weaving in and out of multiple elements.
            original_nwm_ele_mappping[nwm_fid] = ele

    relocated_ele_nwm_mapping = json.load(
        open(f'{relocated_source_sink_dir}/sources.json', 'r')
    )

    relocated_ele_mapping = {}
    seen_original_eles = set()
    for ele, nwm_fids in relocated_ele_nwm_mapping.items():
        if nwm_fids == []:
            raise ValueError(f'Relocated source element {ele} has no NWM feature IDs!')
        relocated_ele_mapping[ele] = []
        for nwm_fid in nwm_fids:
            if nwm_fid not in original_nwm_ele_mappping:
                raise ValueError(f'Relocated source element {ele} has NWM fid {nwm_fid} '
                                 'not found in original source elements!')
            # when an original ele corresponds to multiple NWM fids, relocated_ele_mapping[ele] may have duplicates
            # , so we remove duplicates here
            target_original_ele = original_nwm_ele_mappping[nwm_fid]
            if target_original_ele not in seen_original_eles:
                relocated_ele_mapping[ele].append(target_original_ele)
                seen_original_eles.add(target_original_ele)

    # double check that each original source element is mapped to only one relocated source element
    seen = set()
    for eles in relocated_ele_mapping.values():
        for ele in eles:
            if ele in seen:
                raise ValueError(
                    f"Original source element {ele} is mapped to multiple relocated source elements"
                )
            seen.add(ele)

    vsource_data = np.zeros((original_ss.vsource.n_time, len(relocated_ele_mapping)), dtype=float)
    for i, [relocated_ele, original_eles] in enumerate(relocated_ele_mapping.items()):
        for original_ele in original_eles:
            vsource_data[:, i] += original_ss.vsource.df[original_ele].values

    # assemble relocated vsource.th and msource.th
    relocated_vsource = TimeHistory(
        data_array=np.c_[original_ss.vsource.time, vsource_data], columns=list(relocated_ele_mapping.keys())
    )

    relocated_msource_data = np.ones((original_ss.vsource.n_time, len(relocated_ele_mapping)), dtype=float)
    relocated_msource_list = [
        TimeHistory(
            data_array=np.c_[original_ss.vsource.time, relocated_msource_data*-9999],
            columns=list(relocated_ele_mapping.keys())
        ),  # Temperature
        TimeHistory(
            data_array=np.c_[original_ss.vsource.time, relocated_msource_data*0],
            columns=list(relocated_ele_mapping.keys())
        )  # Salinity
    ]

    return relocated_vsource, relocated_msource_list


def assemble_source_sink(config, hgrid, model_input_path=None, wdir=None):
    """
    Assemble source/sink files for SCHISM model
    The assembled source/sink files include:
        vsource.th, vsink.th, msource.th, source_sink.in, source.nc,
        sources.json, sinks.json
    """

    if config.hgrid_without_feeders is not None:
        print(
            'Normal case: beside the main hgrid, '
            f'an hgrid without feeders is provided: {config.hgrid_without_feeders}, '
            'assuming the main hgrid has feeders!'
        )
        main_hgrid_has_feeder = True
    else:
        print(
            'Special case: only the main hgrid is provided,'
            'assuming the main hgrid has NO feeders!'
            'Caution: you should not search for NWM source/sink on a grid with feeders!'
        )
        main_hgrid_has_feeder = False

    # '''  comment out the following code in triple quotes to skip generating original source_sink files
    # ----------------------Generate original source_sink files ----------------------

    # generate source_sink files by intersecting NWM river segments
    # with the model land boundary
    mkcd_new_dir(f'{wdir}/original_source_sink/')
    if config.hgrid_without_feeders is not None:
        os.symlink(f'{config.hgrid_without_feeders}', 'hgrid.gr3')
    else:
        os.symlink(f'{model_input_path}/hgrid.gr3', 'hgrid.gr3')

    # copy existing sources.json and sinks.json
    if config.existing_source_json_path is not None:
        print('reusing existing sources.json and sinks.json ...')
        if os.path.exists(f'{config.existing_source_json_path}/sources.json'):
            os.system(f'cp -rf {config.existing_source_json_path}/sources.json .')
        else:
            print(
                f'Warning: specified {config.existing_source_json_path}/sources.json does not exist, '
                'generating it from scratch ...'
            )
        if os.path.exists(f'{config.existing_source_json_path}/sinks.json'):
            os.system(f'cp -rf {config.existing_source_json_path}/sinks.json .')
        else:
            print(
                f'Warning: specified {config.existing_source_json_path}/sinks.json does not exist, '
                'generating it from scratch ...'
            )

    actual_nwm_cache_folder = gen_sourcesink_nwm(
        hgrid_fname='./hgrid.gr3',  # current directory: {model_input_path}/{sub_dir}/original_source_sink/
        startdate=config.startdate, rnday=config.rnday,
        cache_folder=config.nwm_cache_folder)

    if config.nwm_cache_folder is None:
        config.nwm_cache_folder = actual_nwm_cache_folder
        print(f'Setting config.nwm_cache_folder to {actual_nwm_cache_folder}')
    elif Path(actual_nwm_cache_folder).resolve(strict=True) != Path(config.nwm_cache_folder).resolve(strict=True):
        print(
            f'Warning: the actual nwm_cache_folder has been generated at {actual_nwm_cache_folder}, '
            'different from the specified config.nwm_cache_folder {config.nwm_cache_folder}, '
            'make sure this is intended!'
        )
        config.nwm_cache_folder = actual_nwm_cache_folder
    # '''

    # ---------------------- replace NWM sources with USGS observed flow rates ----------------------
    # Note: this is optional, depending on the availability of USGS data
    if config.replace_nwm_with_usgs:
        print('replacing NWM sources with USGS observed flow rates ...')
        # this will save the original_ss_dir to original_source_sink_before_USGS_adjustment
        # and overwrite original_ss_dir/vsource.th with adjusted_vsource.th
        source_nwm2usgs(
            start_time_str=config.startdate.strftime('%Y-%m-%d %H:%M:%S'),
            states=STOFS3D_ATL_STATES,
            f_shapefile="/sciclone/schism10/Hgrid_projects/NWM/ecgc/ecgc.shp",
            original_ss_dir=f'{wdir}/original_source_sink/',
            nwm_data_dir=config.nwm_cache_folder,
            output_dir=f'{wdir}/USGS_adjusted_sources/',
        )

    # A single NWM segment weaving in and out will create duplicate sources/sinks
    # , so it is not necessary to remove duplicates here.
    # The code may be reusable, so it is kept here.
    #
    # # find any duplicate sources
    # with open(
    #     f'{wdir}/original_source_sink/sources.json',
    #     'r', encoding='utf-8'
    # ) as f:
    #     old_sources2fids = json.load(f)
    # fid_list = [fid for fids in old_sources2fids.values() for fid in fids]
    # if len(fid_list) != len(set(fid_list)):
    #     print(f'Number of duplicated fids: {len(fid_list) - len(set(fid_list))}')
    #     # raise ValueError('Duplicated fids in new2fid')

    #     for fid in set(fid_list):
    #         if fid_list.count(fid) > 1:
    #             print(f'Duplicated fid: {fid}')

    #     # backup the original source_sink files
    #     os.system(f'cp -r {wdir}/original_source_sink/ '
    #               f'{wdir}/original_source_sink_0/')

    #     # remove duplicated sources in the original source_sink files
    #     old_sources2fids = remove_duplicate_dict_values(old_sources2fids)
    #     # remove keys with empty values
    #     old_sources2fids = {k: v for k, v in old_sources2fids.items() if v}

    #     # regenerate old sources based on updated old_sources2fids
    #     with open(
    #         f'{wdir}/original_source_sink/sources.json',
    #         'w', encoding='utf-8'
    #     ) as f:
    #         json.dump(old_sources2fids, f, indent=4)
    #     gen_sourcesink_nwm(
    #         hgrid_fname='./hgrid.gr3',
    #         startdate=config.startdate, rnday=config.rnday,
    #         cache_folder=config.nwm_cache_folder)

    # ---------------------- relocate sources to resolved river channels ----------------------
    # Set proper no_feeder option, mandatory_sources_coor, and feeder_info_file in stofs3d_atl_config.py
    # The result is used as the "base" source/sink in subsequent steps
    if config.relocate_source:
        # relocate
        mkcd_new_dir(f'{wdir}/relocated_source_sink/')
        os.symlink(f'{model_input_path}/hgrid.gr3', 'hgrid.gr3')

        # this will generate relocated sources.json and sinks.json based on the main hgrid,
        # i.e., {model_input_path}/hgrid.gr3
        relocate_sources2(
            old_ss_dir=f'{wdir}/original_source_sink/',
            feeder_info_file=config.feeder_info_file,
            hgrid_fname=f'{model_input_path}/hgrid.gr3',
            outdir=f'{wdir}/relocated_source_sink/',
            max_search_radius=2100, mandatory_sources_coor=config.mandatory_sources_coor,
            allow_neglection=False, main_hgrid_has_feeder=main_hgrid_has_feeder,
        )

        # regenerate vsource.th based on relocated sources.json
        if config.reuse_source_json:
            # This ensures increasing element IDs in source_sink.in
            # gen_sourcesin_nwm requires sinks.json
            os.system(f'ln -sf {wdir}/original_source_sink/sinks.json .')
            gen_sourcesink_nwm(  # with existing sources.json and sinks.json
                hgrid_fname=f'{model_input_path}/hgrid.gr3',
                startdate=config.startdate, rnday=config.rnday,
                cache_folder=config.nwm_cache_folder
            )
            relocated_ss = source_sink.from_files(
                source_dir=f'{wdir}/relocated_source_sink/',
            )  # sinks will be discarded later, only sources will be used
            base_ss = source_sink(
                vsource=relocated_ss.vsource, vsink=None, msource=relocated_ss.msource
            )
        else:
            # Important:
            # This does not enforce increasing element IDs ins source_sink.in
            # For minor updates in operation, use this option, otherwise the order in source_sink.in may be
            # inconsistent with existing sources.json, and all sources/sinks/json files need to be regenerated.
            #
            # In the case the original sources have been adjusted by USGS obs,
            # Don't call gen_sourcesink_nwm again, use gen_relocated_source instead.

            # Note, if USGS adjustment is performed, the original_source_sink is backed up to
            # {wdir}/original_source_sink_before_USGS_adjustment/, and the updated original_source_sink dir
            # has the adjusted vsource.th linked as vsource.th
            relocated_vsource, relocated_msource_list = gen_relocated_source(
                original_source_sink_dir=f'{wdir}/original_source_sink/',
                relocated_source_sink_dir=f'{wdir}/relocated_source_sink/',
            )
            base_ss = source_sink(
                vsource=relocated_vsource, vsink=None, msource=relocated_msource_list)
            base_ss.writer(f'{wdir}/relocated_source_sink/')
    else:
        base_ss = source_sink.from_files(f'{wdir}/original_source_sink/')

    # ---------- set constant sinks (pumps and background sinks) ----------
    mkcd_new_dir(f'{wdir}/constant_sink/')
    # copy *.shp to the current directory
    os.system(f'cp {script_path}/Constant_sinks/levee_pump_polys* .')
    background_ss = set_constant_sink(
        wdir=f'{wdir}/constant_sink/',
        shapefile_name='levee_pump_polys_2025_with_poly_type.shp',
        hgrid=hgrid,  # lon/lat
    )

    # ------------- assemble source/sink files and write to files ------------
    total_ss = base_ss + background_ss
    total_ss.writer(f'{wdir}/')

    # the final source/sink uses the relocated sources and constant sinks (no json needed)
    os.chdir(f'{wdir}')
    if config.relocate_source:
        os.system('ln -sf ./relocated_source_sink/sources.json .')
    else:
        os.system('ln -sf ./original_source_sink/sources.json .')

    # temporary fix for isolated feeder channels; Note this doesn't change sources.json or source.nc
    if config.source_ele_replace_dict is not None:
        from .patch_feeder_source_sink_in import replace_ele_in_source_sink
        replace_ele_in_source_sink(wdir, config.source_ele_replace_dict)

    # -------------------------- write diagnostic outputs --------------------------
    hgrid.compute_ctr()

    # source
    src_idx = np.asarray(total_ss.source_eles) - 1
    src = np.column_stack((
        np.asarray(hgrid.xctr)[src_idx],
        np.asarray(hgrid.yctr)[src_idx],
        total_ss.vsource.df.values.mean(axis=0)
    ))
    np.savetxt(
        f"{wdir}/vsource.xyz",
        src, fmt="%.6f", header="lon lat vsource", comments=""
    )

    # sink
    snk_idx = np.asarray(total_ss.sink_eles) - 1
    snk = np.column_stack((
        np.asarray(hgrid.xctr)[snk_idx],
        np.asarray(hgrid.yctr)[snk_idx],
        total_ss.vsink.df.values.mean(axis=0)
    ))
    np.savetxt(
        f"{wdir}/vsink.xyz",
        snk, fmt="%.6f", header="lon lat vsink", comments=""
    )


def sample2():
    '''
    Subsetting example workflow for STOFS3D Atlantic v7.2,
    assuming the original source_sink files have already
    been generated by gen_sourcesink_nwm
    '''
    from datetime import datetime
    from .Relocate.relocate_source_feeder import (
        v19p2_for_sms_v27_mandatory_sources_coor, relocate_sources2
    )
    import geopandas as gpd
    from shapely import get_coordinates
    from pylib import schism_grid as schism_read
    from pylib_experimental.schism_file import source_sink

    # --------------inputs -----------------
    wdir = '/sciclone/schism10/feiye/TEMP/clip_by_polygon/I03/Source_sink/'
    main_hgrid_fname = f'{wdir}/hgrid.gr3'
    # hgrid_without_feeders_fname = main_hgrid_fname

    startdate = datetime(2018, 8, 30)
    rnday = 10

    region_gdf = gpd.read_file(
        '/sciclone/schism10/feiye/TEMP/clip_by_polygon/hires/hires_buffered.shp'
    ).to_crs('EPSG:4326')
    # -------------------- end inputs -----------------

    os.chdir(wdir)
    region_list = [get_coordinates(p) for p in region_gdf.explode(index_parts=True).exterior]

    # generate original source_sink files
    # use hgrid_without_feeders (if available) to generate original source_sink files
    # if hgrid_without_feeders is not available, use the main hgrid directly
    # For this sample, the main hgrid is used directly.
    # os.makedirs(f'{wdir}/original_source_sink/', exist_ok=True)
    # os.chdir(f'{wdir}/original_source_sink/')
    # os.system(f'ln -sf {main_hgrid_fname} hgrid.gr3')
    # cache_folder = gen_sourcesink_nwm(
    #     hgrid_fname=hgrid_without_feeders_fname,
    #     startdate=startdate, rnday=rnday,
    #     cache_folder=None,
    # )

    print('read original source/sink')
    original_ss = source_sink.from_files(source_dir=f'{wdir}/original_source_sink/')

    print('subsetting original source/sink by polygons')
    inside_ss, outside_ss = original_ss.clip_by_polygons(
        hgrid=schism_read(f'{wdir}/original_source_sink/hgrid.gr3'),  # can also use pylib's read()
        polygons_xy=region_list
    )
    inside_ss.writer(f'{wdir}/inside_source_sink/')
    os.system(f'ln -sf {main_hgrid_fname} {wdir}/inside_source_sink/hgrid.gr3')
    outside_ss.writer(f'{wdir}/outside_source_sink/')
    os.system(f'ln -sf {main_hgrid_fname} {wdir}/outside_source_sink/hgrid.gr3')

    # relocate sources in high-res regions (inside_ss) on the main hgrid
    # subset sources.json and sinks.json in the high-res regions based on the original source_sink files
    for i, json_file in enumerate(['sources.json', 'sinks.json']):
        original_ele2nwm_fid = json.load(open(
            f'{wdir}/original_source_sink/{json_file}', 'r', encoding='utf-8'
        ))
        ele2nwm_fid = {
            str(int(k)): v for k, v in original_ele2nwm_fid.items()
            if int(k) in inside_ss.source_sink_in.ip_group[i]
        }
        with open(f'{wdir}/inside_source_sink/{json_file}', 'w', encoding='utf-8') as f:
            json.dump(ele2nwm_fid, f, indent=4)

    print('generate sources.json for relocated sources on the main hgrid')
    relocate_sources2(
        old_ss_dir=f'{wdir}/inside_source_sink/',
        feeder_info_file='/sciclone/schism10/Hgrid_projects/STOFS3D-v8/v31/Feeder/feeder_heads_bases.xy',
        hgrid_fname=main_hgrid_fname, outdir=f'{wdir}/relocated_source_sink/',
        max_search_radius=2100, mandatory_sources_coor=v19p2_for_sms_v27_mandatory_sources_coor,
        allow_neglection=True, region_list=region_list
    )

    print('generate relocated source/sink')
    os.chdir(f'{wdir}/relocated_source_sink/')
    os.system(f'ln -sf {wdir}/inside_source_sink/sinks.json .')
    gen_sourcesink_nwm(  # with existing sources.json and sinks.json
        hgrid_fname=main_hgrid_fname,
        startdate=startdate, rnday=rnday,
        cache_folder='/sciclone/schism10/feiye/TEMP/clip_by_polygon/I03/Source_sink/original_source_sink/20180830',
        # cache_folder generated by the first call
    )

    print('read relocated source/sink and discard sinks')
    relocated_ss = source_sink.from_files(  # strictly check on duplicates since there should not be any
        source_dir=f'{wdir}/relocated_source_sink/', strict_check=True
    )  # sinks will be discarded later, only sources will be used

    # discard sinks from relocated_ss by setting vsink=None
    relocated_ss = source_sink(
        vsource=relocated_ss.vsource, vsink=None, msource=relocated_ss.msource
    )

    print('combine source/sinks inside and outside the high-res regions')
    combined_ss = outside_ss + relocated_ss
    combined_ss.writer(f'{wdir}/combined_source_sink/')

    print('Done!')


if __name__ == "__main__":
    sample2()
    print('Done!')
