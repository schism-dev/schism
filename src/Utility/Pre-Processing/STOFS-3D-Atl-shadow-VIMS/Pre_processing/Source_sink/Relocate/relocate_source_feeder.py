#!/usr/bin/env python3

'''
Relocate sources/sinks based on the feeder channel information.
See __main__ for sample usage.
'''

import os
from pathlib import Path
import numpy as np
from scipy import spatial

from pylib_essentials.schism_file import source_sink, TimeHistory, read_schism_hgrid_cached, schism_bpfile
from pylib_essentials.utility_functions import inside_polygon

# Global Var
# Some major rivers may not have a feeder channel, or the feeder channel doesn't match the main river inputs.
# In such cases, manually relocate sources with the mandatory_sources_coor array.
# (e.g., by visualizing the map generated by viz_source.py).
# The first two columns are longitude and latitude of the mandatory (relocated) source locations.
# The third and fourth columns are longitude and latitude of the corresponding original source locations.
# If the original source locations are the same as the mandatory source locations,
# the third and fourth columns can be set as np.nan
v16_mandatory_sources_coor = np.array([
    [-69.77256, 44.31494, np.nan, np.nan],  # Kennebec River, ME
    [-73.90869, 42.13509, np.nan, np.nan],  # Hudson River, NY
    [-76.12905866666667, 39.60955966666666, np.nan, np.nan],  # Susquehanna River, VA
    [-74.94442, 40.34478, np.nan, np.nan],  # Delaware River, NJ
    [-78.425288, 34.508177, np.nan, np.nan],  # Cape Fear River, NC
    [-91.72306, 31.04462, np.nan, np.nan],  # Red River (upstream of Atchafalaya River), LA
    [-80.10808, 33.50005, np.nan, np.nan],  # Santee River, SC
    [-79.81703, 33.59694, np.nan, np.nan],  # Black River, SC
    [-79.57210, 33.71223, np.nan, np.nan],  # Black Mingo Creek, SC
    [-79.49997, 33.84686, np.nan, np.nan],  # Lynches River, SC
    [-79.48467, 33.93939, np.nan, np.nan],  # Pee Dee River, SC
    [-79.33247, 33.98196, np.nan, np.nan],  # Little Pee Dee River, SC
    [-77.917829, 34.749979, np.nan, np.nan],  # Northeast Cape Fear River, NC
    [-87.9523, 30.8472, np.nan, np.nan],  # Mobile River, AL
    [-96.695401, 28.968284, -96.69652166667, 28.990345],  # Lavaca River, TX
    [-96.548436, 28.999706, -96.554498, 29.024612666667],  # Lake Texana, TX
    [-93.83342666667, 30.355123333333, -93.83342666667, 30.355123333333],  # Cypress Creek, TX
    [-89.764476, 30.551926, -89.76781133333, 30.538070666667],  # Lotts Creek, LA
    [-87.219805, 30.567296, -87.24471466667, 30.601442333333],  # Escambia River, FL
    [-83.987035, 30.331327, np.nan, np.nan],  # Horsehead Creek and Little River, FL
    [-83.928038, 30.30404, np.nan, np.nan],  # Bailey Mill Creek, FL
    [-82.950913, 29.958097, -82.99605566667, 30.007415],  # Suwannee River, FL
    [-81.02370433333333, 27.315079666666666, np.nan, np.nan],  # Kissimmee River, FL
    [-81.997572, 30.786870, -82.040457, 30.74494233333333],  # St Marys River, FL
    [-79.43425, 33.84487, -79.50974266666667, 33.85385866666667],  # Lyches River, SC
    [-74.74868, 39.47915, -74.75470666666668, 39.485390333333335],  # Great Egg Harbor River, NJ
    [-73.94009733333333, 42.06972966666667, np.nan, np.nan],  # Saugeties Creek, NY
    [-73.971293, 41.920595999999996, np.nan, np.nan],  # Hudson River branch, NY
    [-73.92918633333333, 41.592421333333334, np.nan, np.nan],  # Hudson River branch, NY
    [-73.07229533333333, 41.303546000000004, np.nan, np.nan],  # Housatonic River, CT
    [-72.625735, 41.656137666666666, np.nan, np.nan],  # Connecticut River, CT
    [-72.64970633333333, 41.572111666666665, np.nan, np.nan],  # Mattabesset River, CT
    [-72.470818, 41.47020933333334, np.nan, np.nan],  # Salmon River, CT
    [-72.11158266666666, 41.455657333333335, np.nan, np.nan],  # Stony Brook, CT
    [-72.090553, 41.535118000000004, np.nan, np.nan],  # Yantic River, CT
    [-72.06195833333334, 41.525600000000004, np.nan, np.nan],  # Quinebaug River, CT
]).reshape(-1, 4)

v19p2_mandatory_sources_coor = np.array([
    [-73.90869, 42.13509, np.nan, np.nan],  # Hudson River, NY
    [-74.94442, 40.34478, np.nan, np.nan],  # Delaware River, NJ
    [-76.132095, 39.603897, np.nan, np.nan],  # Susquehanna River, VA
    [-78.425288, 34.508177, np.nan, np.nan],  # Cape Fear River, NC
    [-91.72306, 31.04462, np.nan, np.nan],  # Red River (upstream of Atchafalaya River), LA
    [-80.10808, 33.50005, np.nan, np.nan],  # Santee River, SC
    [-79.81703, 33.59694, np.nan, np.nan],  # Black River, SC
    [-79.57210, 33.71223, np.nan, np.nan],  # Black Mingo Creek, SC
    [-79.49997, 33.84686, np.nan, np.nan],  # Lynches River, SC
    [-79.48467, 33.93939, np.nan, np.nan],  # Pee Dee River, SC
    [-79.33247, 33.98196, np.nan, np.nan],  # Little Pee Dee River, SC
    [-77.917829, 34.749979, np.nan, np.nan],  # Northeast Cape Fear River, NC
    [-87.9523, 30.8472, np.nan, np.nan],  # Mobile River, AL
    [-96.695401, 28.968284, -96.69652166667, 28.990345],  # Lavaca River, TX
    [-96.548436, 28.999706, -96.554498, 29.024612666667],  # Lake Texana, TX
    [-93.83342666667, 30.355123333333, -93.83342666667, 30.355123333333],  # Cypress Creek, TX
    [-89.764476, 30.551926, -89.76781133333, 30.538070666667],  # Lotts Creek, LA
    [-87.219805, 30.567296, -87.24471466667, 30.601442333333],  # Escambia River, FL
    [-83.987035, 30.331327, np.nan, np.nan],  # Horsehead Creek and Little River, FL
    [-83.928038, 30.30404, np.nan, np.nan],  # Bailey Mill Creek, FL
    [-82.950913, 29.958097, -82.99605566667, 30.007415],  # Suwannee River, FL
    [-81.02370433333333, 27.315079666666666, np.nan, np.nan],  # Kissimmee River, FL
    [-81.997572, 30.786870, -82.040457, 30.74494233333333],  # St Marys River, FL
    [-91.56184, 31.05043, np.nan, np.nan],  # Mississippi River
    [-79.43425, 33.84487, -79.50974266666667, 33.85385866666667],  # Lyches River, SC
    [-74.74868, 39.47915, -74.75470666666668, 39.485390333333335],  # Great Egg Harbor River, NJ
    [-73.94009733333333, 42.06972966666667, np.nan, np.nan],  # Saugeties Creek, NY
    [-73.971293, 41.920595999999996, np.nan, np.nan],  # Hudson River branch, NY
    [-73.92918633333333, 41.592421333333334, np.nan, np.nan],  # Hudson River branch, NY
    [-73.07229533333333, 41.303546000000004, np.nan, np.nan],  # Housatonic River, CT
    [-72.625735, 41.656137666666666, np.nan, np.nan],  # Connecticut River, CT
    [-72.64970633333333, 41.572111666666665, np.nan, np.nan],  # Mattabesset River, CT
    [-72.470818, 41.47020933333334, np.nan, np.nan],  # Salmon River, CT
    [-72.11158266666666, 41.455657333333335, np.nan, np.nan],  # Stony Brook, CT
    [-72.090553, 41.535118000000004, np.nan, np.nan],  # Yantic River, CT
    [-72.06195833333334, 41.525600000000004, np.nan, np.nan],  # Quinebaug River, CT
]).reshape(-1, 4)


def nearest_neighbour(points_a, points_b):
    tree = spatial.cKDTree(points_b)
    return np.array(tree.query(points_a)[1]).reshape(-1,), np.array(tree.query(points_a)[0]).reshape(-1,)

def dist(points_group_A, points_group_B):
    points_A = np.squeeze(points_group_A.view(np.complex128))
    points_B = np.squeeze(points_group_B.view(np.complex128))
    return np.absolute(points_A-points_B)

def lonlat2cpp(lon, lat, lon0=0, lat0=0):
    R = 6378206.4

    lon_radian, lat_radian = lon/180*np.pi, lat/180*np.pi
    lon0_radian, lat0_radian = lon0/180*np.pi, lat0/180*np.pi

    xout = R * (lon_radian - lon0_radian) * np.cos(lat0_radian)
    yout = R * lat_radian

    return [xout, yout]


def relocate_sources(
    old_ss_dir=None,
    feeder_info_file=None,
    hgrid_fname=None,
    outdir=None,
    max_search_radius = 1000.0,
    mandatory_sources_coor = np.empty((0, 4)),
    relocate_map = None,
    region_list = [],  # a list of polygons, each specified by a 2D array (npts, 2) of coordinates
    allow_neglection = True,  # allow neglecting channels that cannot be matched to a new source location in the relocation process
                              # this is useful when the relocation is only for a specific region
                              #  ; if False, the unassigned old sources will be linked to the closest new source
    #--------------------------- end inputs -------------------------
):
    # make the output directory if it doesn't exist
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # Read original source/sink based on NWM
    old_source_sink = source_sink.from_files(source_dir=old_ss_dir)

    if relocate_map is None:  # if the relocation map is not provided, it needs to be generated here

        # -------------------------------------info from old source_sink-------------------------------------
        # get old hgrid (without feeders); hgrid with feeders may also be used
        old_gd = read_schism_hgrid_cached(f'{old_ss_dir}/hgrid.gr3', overwrite_cache=False)

        # get old source coordinates
        old_gd.compute_ctr()
        # Note: source_eles starts from 1; mean vsource is added as the z field for diagnostics
        old_sources_coor = np.c_[old_gd.xctr[old_source_sink.source_eles-1], old_gd.yctr[old_source_sink.source_eles-1],
                                 old_source_sink.vsource.df.mean().values]
        np.savetxt(f'{old_ss_dir}/original_sources.xy', old_sources_coor)

        # -------------------------------------info on feeders-------------------------------------
        # Read feeder channel info, which is generated by make_feeder_channel.py
        # ".pkl" and "*.xy" are both generated; the latter is preferred because it is human readable
        if Path(feeder_info_file).suffix == '.pkl':
            import pickle
            with open(feeder_info_file, 'rb') as file:
                [feeder_l2g, feeder_points, feeder_heads, feeder_bases] = pickle.load(file)
            np.savetxt(f'{outdir}/feeder_heads_bases.xy', np.c_[feeder_heads[:, :2], feeder_bases[:, :2]])
        elif Path(feeder_info_file).suffix == '.xy':
            tmp = np.loadtxt(feeder_info_file)
            feeder_heads = tmp[:, :2]
            feeder_bases = tmp[:, 2:]
        else:
            raise ValueError('feeder info file must be .pkl or .xy')

        # -------------------------------------new hgrid-------------------------------------
        # get new hgrid (with feeders)
        new_gd = read_schism_hgrid_cached(hgrid_fname, overwrite_cache=False)
        new_gd.compute_ctr()

        # -------------------------------------manual intervetion as pre-requisits -------------------------------------
        # process nan values in mandatory_sources_coor
        for i, row in enumerate(mandatory_sources_coor):
            if np.isnan(row[2]):
                mandatory_sources_coor[i, 2] = mandatory_sources_coor[i, 0]
            if np.isnan(row[3]):
                mandatory_sources_coor[i, 3] = mandatory_sources_coor[i, 1]
        
        # restrict the relocation to regions if specified
        if region_list != []:
            idx = np.zeros(len(feeder_heads), dtype=bool)
            for region in region_list:
                idx += inside_polygon(feeder_heads[:, :2], region[:, 0], region[:, 1]).astype(bool)
            if any(idx):  # subset if any feeder is in regions
                feeder_heads = feeder_heads[idx]
                feeder_bases = feeder_bases[idx]

            for region in region_list: 
                idx = inside_polygon(mandatory_sources_coor[:, :2], region[:, 0], region[:, 1]).astype(bool)
            if any(idx):
                mandatory_sources_coor = mandatory_sources_coor[idx]

        # -------------------------------------relocation-------------------------------------
        # Find matching source point at mandatory_sources_coor and feeders
        # These are the desired new source locations
        new_sources_coor = np.r_[mandatory_sources_coor[:, :2], feeder_heads[:, :2]]
        # These are the locations used to search for the closest old source
        # ; in other words, to link the new source to the old source.
        # For the mandatory sources, these may be different from the new source locations
        # to allow for more reasonable matching between the old source location and the new source location
        # than the direct distance between the new sources and the old sources.
        # For example, it makes sense to use the feeder base to search for the closest old source,
        # but the new source should be placed at the feeder head.
        new_sources_search_point_coor = np.r_[mandatory_sources_coor[:, 2:4], feeder_bases[:, :2]]

        # get new source elements (ele_idx, 0-based indexing)
        new_sources_ele_idx, _ = nearest_neighbour(new_sources_coor, np.c_[new_gd.xctr, new_gd.yctr])

        # projection from lon/lat to meters
        old_sources_x, old_sources_y = lonlat2cpp(old_sources_coor[:, 0], lat=old_sources_coor[:, 1])
        # Note: new_sources_x and y are based on new_sources_search_point_coor
        new_sources_x, new_sources_y = lonlat2cpp(new_sources_search_point_coor[:, 0], new_sources_search_point_coor[:, 1])

        # link each new source to the closest old source
        # mandatory sources are always relocated despite the distance
        linked_old_source_id = {}   # keep a record of the old source id linked to a new source
        new2old_sources = - np.ones(len(new_sources_x), dtype=int)
        relocation_distance = np.zeros(len(new_sources_x))
        old_vsource_mean = old_source_sink.vsource.df.mean().values
        for i, [x, y] in enumerate(zip(new_sources_x, new_sources_y)):
            # for each new source, find the old sources within the search radius
            dist = np.sqrt((old_sources_x - x)**2 + (old_sources_y - y)**2)
            valid_old_sources = np.argwhere(dist < max_search_radius).reshape(-1,)
            if len(valid_old_sources) > 0:
                # within valid_old_sources, choose the one with the largest mean flow,
                # it is likely the correct old source because the new sources are on larger channels
                target_old_source = valid_old_sources[np.argmax(old_vsource_mean[valid_old_sources])]
                new2old_sources[i] = target_old_source  # this holds the index of the old source in source_sink.in, not element idx or id
                relocation_distance[i] = dist[target_old_source]
            else:
                if i < len(mandatory_sources_coor):
                    raise ValueError(f'mandatory new source {i}: {x, y} cannot be mapped to an old source')

        # -------------------------------------clean up odd cases-------------------------------------
        # check if multiple new sources are linked to the same old source, i.e., double-counting an old source
        for old_source in np.unique(new2old_sources):
            if old_source == -1: continue  # skip invalid new sources

            ids = np.argwhere(new2old_sources == old_source)  # find all new sources mapped to the same old source
            if len(ids) == 0:
                print(f'old source {old_source} cannot be mapped to a new source')
            elif len(ids) == 1:  # exact match
                pass
            else:  # multiple new sources mapped to the same old source, only retain the closest new source
                min_dist_id = np.argmin(relocation_distance[ids])
                new2old_sources[ids] = -1  # remove all corresponding new sources first
                new2old_sources[ids[min_dist_id]] = old_source  # keep the closest new source

        valid_new_sources_eleids = new_sources_ele_idx[new2old_sources>=0] + 1  # add 1 to get element ids (1-based indexing)
        valid_new2old_sources = new2old_sources[new2old_sources>=0]  # 0-based index of the old source in source_sink.in, not element idx or id

        # sanity check
        if np.unique(valid_new_sources_eleids).shape[0] != valid_new_sources_eleids.shape[0]:
            raise ValueError('Multiple new sources')
        if np.unique(valid_new2old_sources).shape[0] != valid_new2old_sources.shape[0]:
            raise ValueError('Multiple old sources')

        if not allow_neglection: # find the remaining unassigned old sources
            unassigned_old_sources_idx = [i for i in range(len(old_sources_coor)) if i not in valid_new2old_sources]
            # find the closest new source to each unassigned old source
            unassigned2new_idx, _ = nearest_neighbour(np.c_[old_sources_x[unassigned_old_sources_idx], old_sources_y[unassigned_old_sources_idx]], np.c_[new_sources_x, new_sources_y])
            # add the unassigned old sources to the valid relocation
            valid_new_sources_eleids = np.r_[valid_new_sources_eleids, new_sources_ele_idx[unassigned2new_idx] + 1]  # new_sources_ele_idx starts from 0, add 1 to get element ids (1-based indexing)
            valid_new2old_sources = np.r_[valid_new2old_sources, unassigned_old_sources_idx]

        # -------------------------------------write relocation map-------------------------------------
        # this can also be used as an input for other runs with the same grid setup to bypass the relocation process
        np.savetxt(f'{outdir}/relocate_map.txt', np.c_[valid_new_sources_eleids, valid_new2old_sources], fmt='%d %d')
    else:
        valid_new_sources_eleids = relocate_map[:, 0]; valid_new2old_sources = relocate_map[:, 1]

    # -------------------------------------write all outputs-------------------------------------
    # assemble source_sink object
    nsources = len(valid_new_sources_eleids)
    msource_list = []
    for old_msource in old_source_sink.msource:
        msource_list.append(
            TimeHistory(
                data_array=np.c_[old_msource.time, old_msource.data[:, valid_new2old_sources]],
                columns=['datetime'] + valid_new_sources_eleids.astype('str').tolist()
            )
        )
    
    vsource = TimeHistory(
        data_array=np.c_[old_source_sink.vsource.time, old_source_sink.vsource.data[:, valid_new2old_sources]],
        columns=['datetime'] + valid_new_sources_eleids.astype('str').tolist()
    )

    new_source_sink = source_sink(vsource=vsource, msource=msource_list, vsink=None)
    new_source_sink.writer(outdir)

    # Note: source_eles starts from 1
    new_sources_coor = np.c_[
        new_gd.xctr[new_source_sink.source_sink_in.ip_group[0]-1],
        new_gd.yctr[new_source_sink.source_sink_in.ip_group[0]-1],
        vsource.df.mean().values
    ]
    np.savetxt(f'{outdir}/relocated_sources.xyz', new_sources_coor)

    return new_source_sink

def samples():
    '''
    Sample usage: relocate sources/sinks in a region of the Florence mesh.
    The mesh is same as the mesh of STOFS-3D-Atl v2.1 in the Florence region and coarser elsewhere.
    '''
    schism_git_dir = f'/sciclone/data10/feiye/SCHISM_REPOSITORY/schism/'
    # inputs
    wdir = '/sciclone/schism10/feiye/Test_Project/Runs/R99a/Source_sink/'
    feeder_info_file = f'{schism_git_dir}/src/Utility/Pre-Processing/STOFS-3D-Atl-shadow-VIMS/Pre_processing/Source_sink/feeder_heads_bases_v2.1.xy'  # this file is prepared during mesh generation  # f'/sciclone/schism10/feiye/STOFS3D-v5/Inputs/v14/Parallel/SMS_proj/feeder/feeder.pkl'
    region_file = f'{schism_git_dir}/src/Utility/Pre-Processing/STOFS-3D-Atl-shadow-VIMS/Pre_processing/Source_sink/relocate_florence.reg'
    old_ss_dir = f'{wdir}/original_source_sink/'
    hgrid_fname = f'{old_ss_dir}/hgrid.gr3'
    # end inputs

    # copy data files from git to the working directory for record if needed

    # read hgrid
    hgrid = read_schism_hgrid_cached(hgrid_fname, overwrite_cache=False)

    # read region
    region = schism_bpfile()
    region.read_reg(fname=region_file) 

    # read original source/sink
    original_ss = source_sink.from_files(source_dir=old_ss_dir)
    # original_ss.diag_writer(hgrid, old_ss_dir)

    # split source/sink into inside and outside region
    _, outside_ss = original_ss.clip_by_polygons(hgrid=hgrid, polygons_xy=[np.c_[region.x, region.y]])

    # relocate sources
    relocated_ss = relocate_sources(
        old_ss_dir=old_ss_dir,  # strictly speaking, this is based on the without feeder hgrid, but the with feeder hgrid is also applicable with minor differences in the results
        feeder_info_file=feeder_info_file,  
        hgrid_fname=hgrid_fname,  # strictly speaking, this is the with feeder hgrid
        outdir=f'{wdir}/relocated_source_sink/',
        max_search_radius=2000, # search radius (in meters) for relocating sources
        mandatory_sources_coor=v16_mandatory_sources_coor,
        relocate_map=None,
        region_list=[np.c_[region.x, region.y]]
    )

    # combine outside and relocated sources
    combined_ss = outside_ss + relocated_ss
    combined_ss.writer(f'{wdir}/combined_source_sink/')
    # combined_ss.diag_writer(hgrid, f'{wdir}/combined_source_sink/')

def test():
    wdir = '/sciclone/schism10/feiye/STOFS3D-v7/Inputs/I12x/Source_sink1/relocated_source_sink/'
    relocated_ss = relocate_sources(
        old_ss_dir=f'/sciclone/schism10/feiye/STOFS3D-v7/Inputs/I12x/Source_sink1/original_source_sink/',
        feeder_info_file = f'/sciclone/schism10/Hgrid_projects/STOFS3D-v7/v20.0/Feeder/feeder_heads_bases.xy',
        hgrid_fname=f'{wdir}/hgrid.gr3',
        outdir=wdir,
        max_search_radius=2100, mandatory_sources_coor=v19p2_mandatory_sources_coor, relocate_map=None,
        allow_neglection=True
    )
    relocated_ss.writer(wdir)


if __name__ == "__main__":
    test()
    pass